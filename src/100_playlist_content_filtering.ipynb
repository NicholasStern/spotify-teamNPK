{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content filtering using cosine similarity of tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook illustrates our content filtering approach that uses track similarity (measured by cosine distance) to recommend tracks to playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity measures the orientation of two *n*-dimensional sample vectors irrespective to their magnitude. It is calculated by the dot product of two numeric vectors, and it is normalized by the product of the vector lengths. \n",
    "The output value ranges from 0 to 1, with 1 as the highest similarity.\n",
    "\n",
    "We compute a similarity matrix for tracks by using sklearn pairwise distance method, with cosine similairty:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h><center>$cos(\\pmb track_1, \\pmb track_2) = \\frac {\\pmb track_1 \\cdot \\pmb track_2}{||\\pmb track_1|| \\cdot ||\\pmb track_2||}$ </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "subset100 = pd.read_csv(\"../raw_data/track_meta_100subset_new.csv\")\n",
    "subset100 = shuffle(subset100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "### 1.1 Train-test split\n",
    "We split the data into training and test set by 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(subset100, test_size=0.2, random_state=42, stratify = subset100['Playlistid'])\n",
    "# train, val = train_test_split(train, test_size=0.2, random_state=42, stratify = train['Playlistid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data cleaning\n",
    "We drop some non-numeric features in order to calculate the cosine similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features here\n",
    "features_drop = [\"Playlistid\",\"Playlist\",\"Album\", \"Track\", \"Artist\", \"Trackid\", \"Artist_Name\", \"Track_Name\", \"Album_Name\", \"Artist_uri\", \"Track_uri\", \"Album_uri\", \"artist_genres\", \"explicit\"]\n",
    "train_cleaned, test_cleaned = train.drop(features_drop, axis =1), test.drop(features_drop, axis=1)\n",
    "train = train.reset_index(drop=True)\n",
    "train_cleaned = train_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track_Duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219683</td>\n",
       "      <td>0.71600</td>\n",
       "      <td>84</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>-9.349</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>95.063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249533</td>\n",
       "      <td>0.01610</td>\n",
       "      <td>76</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>-6.162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>150.053</td>\n",
       "      <td>4</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220573</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>67</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>-3.838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>185.063</td>\n",
       "      <td>4</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275840</td>\n",
       "      <td>0.19000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>-8.735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>114.812</td>\n",
       "      <td>4</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173493</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>53</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-9.159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>80.511</td>\n",
       "      <td>4</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Track_Duration  acousticness  artist_popularity  danceability  energy  \\\n",
       "0          219683       0.71600                 84         0.505   0.397   \n",
       "1          249533       0.01610                 76         0.680   0.687   \n",
       "2          220573       0.00502                 67         0.551   0.836   \n",
       "3          275840       0.19000                100         0.735   0.410   \n",
       "4          173493       0.23800                 53         0.670   0.558   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.000000    5    0.0853    -9.349     1       0.3240   95.063   \n",
       "1          0.000000    9    0.2610    -6.162     0       0.0709  150.053   \n",
       "2          0.000021   10    0.0425    -3.838     0       0.0524  185.063   \n",
       "3          0.000000   11    0.3410    -8.735     0       0.2000  114.812   \n",
       "4          0.000000    2    0.1060    -9.159     1       0.0251   80.511   \n",
       "\n",
       "   time_signature  valence  \n",
       "0               1    0.558  \n",
       "1               4    0.467  \n",
       "2               4    0.758  \n",
       "3               4    0.164  \n",
       "4               4    0.630  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create a cosine-similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_cleaned)\n",
    "train_scaled = scaler.transform(train_cleaned)\n",
    "test_scaled = scaler.transform(test_cleaned)\n",
    "\n",
    "train_scaled_cos_matrix = cosine_similarity(train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the cosine matrix shows 1970 unique tracks (in 100 playlists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2463, 2463)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled_cos_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote a function to compute prediction set per playlist.\n",
    "\n",
    "The function takes in a pre-calculated track cosine similarity matrix, training set, the target playlist id and the prediction set size (which we pre-determine it to be test set size * 15). It returns a list of tracks (prediction list) to recommend per playlist. The prediction list contains top k similar songs (based on cosine similarity) per track in the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similar_songs_playlist(cos_matrix, orig_df, target_playlist_id, cand_list_size):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    cos_matrix: cosine matrix of the tracks\n",
    "    orig_df: original df with tracks as rows, but with playlistid and other features (e.g., train)\n",
    "    target_playlist_id: id of the target playlist\n",
    "    target_playlist_inx: index of playlist in the training set\n",
    "    cand_list_size: candidate list of songs to recommend size (= test-set size * 15)\n",
    "    \n",
    "    Output:\n",
    "    k_song_to_recommend: the most similar tracks per track\n",
    "    \"\"\"\n",
    "    target_track_inx = np.where(train[\"Playlistid\"] == target_playlist_id)[0] # index of tracks in training playlist of target playlist\n",
    "    candidate_cos_matrix = cos_matrix\n",
    "\n",
    "    ## For each song in the playlist, find k similar songs\n",
    "    cand_list = []\n",
    "    # cand_list_size = k*15\n",
    "    k = np.floor(cand_list_size/len(target_track_inx)) # round(cand_list_size/len(target_track_inx))\n",
    "    k_rest = cand_list_size - k*len(target_track_inx)\n",
    "    # e.g., for a candidate list size of 30, get 3 songs for each track first\n",
    "    for inx, i in enumerate(target_track_inx):\n",
    "        candidate_song_rec = candidate_cos_matrix[i, ] #ith row of matrix\n",
    "        candidate_song_rec_inx = np.argsort(candidate_song_rec)\n",
    "        unique_candidate_song_sorted = train['Track_uri'][candidate_song_rec_inx][::-1].drop_duplicates()\n",
    "        tracks_in_target_playlist = train.loc[train[\"Playlistid\"] == target_playlist_id, \"Track_uri\"]\n",
    "        song_to_recommend = np.array(unique_candidate_song_sorted.loc[~unique_candidate_song_sorted.isin(tracks_in_target_playlist)])\n",
    "\n",
    "        if (k_rest != 0 & inx <= k_rest): # 30-24 = 6; for the first 6 tracks recommend k + 1 songs\n",
    "            k_song_to_recommend = song_to_recommend[:int(k+1)]\n",
    "        else:\n",
    "            k_song_to_recommend = song_to_recommend[:int(k)]\n",
    "            \n",
    "        if inx == 0:\n",
    "            cand_list = k_song_to_recommend\n",
    "        else:\n",
    "            cand_list = np.append(cand_list, k_song_to_recommend)\n",
    "    return list(cand_list) # turn np array into list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Performance \n",
    "### 2.1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nholdout(playlist_id, df):\n",
    "    '''Pass in a playlist id to get number of songs held out in val/test set'''\n",
    "    \n",
    "    return len(df[df.Playlistid == playlist_id].Track_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(prediction, val_set):\n",
    "# prediction should be a list of predictions\n",
    "# val_set should be pandas Series of ground truths\n",
    "    score = np.sum(val_set.isin(prediction))/val_set.shape[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NDCG Code Source: https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Test-Set Performance on 100 playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_playlistid = train['Playlistid'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = []\n",
    "ndcgs = []\n",
    "for pid in unique_playlistid: # loop through each playlist\n",
    "#     print(pid)\n",
    "    ps = cos_similar_songs_playlist(train_scaled_cos_matrix, train, pid, nholdout(pid, test)*15)# predictions\n",
    "    vs = test[test.Playlistid == pid].Track_uri # ground truth\n",
    "    \n",
    "#     print(r_precision(ps, vs))\n",
    "    rps.append(r_precision(ps, vs)) # append individual r-precision score\n",
    "    \n",
    "    # NDCG\n",
    "    r = np.zeros(len(ps))\n",
    "    for i, p in enumerate(ps):\n",
    "        if np.any(vs.isin([p])):\n",
    "            r[i] = 1\n",
    "    ndcgs.append(ndcg_at_k(r, len(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. R-Precision:  0.05171355144110563\n",
      "Avg. NDCG:  0.054487469476922304\n",
      "Total Sum:  0.05310051045901397\n"
     ]
    }
   ],
   "source": [
    "avg_rp = np.mean(rps)\n",
    "avg_ndcg = np.mean(ndcgs)\n",
    "print('Avg. R-Precision: ', avg_rp)\n",
    "print('Avg. NDCG: ', avg_ndcg)\n",
    "print('Total Sum: ', np.mean([avg_rp, avg_ndcg]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Performance on 10k playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset10k_seed = pd.read_csv(\"../raw_data/track_meta_milestone3.csv\", index_col=\"Unnamed: 0\")\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset10k_id = np.random.choice(subset10k_seed['Playlistid'].unique(), size = 10000, replace = False)\n",
    "subset10k = subset10k_seed[subset10k_seed['Playlistid'].isin(subset10k_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Data Processing on 10k playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(subset10k, test_size=0.2, random_state=42, stratify = subset10k['Playlistid'])\n",
    "# Drop features here\n",
    "features_drop = [\"Playlistid\",\"Playlist\",\"Album\", \"Track\", \"Artist\", \"Trackid\", \"Artist_Name\", \"Track_Name\", \"Album_Name\", \"Artist_uri\", \"Track_uri\", \"Album_uri\", \"artist_genres\", \"explicit\"]\n",
    "train_cleaned, test_cleaned = train.drop(features_drop, axis =1), test.drop(features_drop, axis=1)\n",
    "train = train.reset_index(drop=True)\n",
    "train_cleaned = train_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_cleaned)\n",
    "train_scaled = scaler.transform(train_cleaned)\n",
    "test_scaled = scaler.transform(test_cleaned)\n",
    "\n",
    "train_scaled_cos_matrix = cosine_similarity(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subset10k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c5ec92759ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubset10k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subset10k' is not defined"
     ]
    }
   ],
   "source": [
    "subset10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_10kplaylistid = train['Playlistid'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = []\n",
    "ndcgs = []\n",
    "for pid in unique_10kplaylistid: # loop through each playlist\n",
    "#     print(pid)\n",
    "    ps = cos_similar_songs_playlist(train_scaled_cos_matrix, train, pid, nholdout(pid, test)*15)# predictions\n",
    "    vs = test[test.Playlistid == pid].Track_uri # ground truth\n",
    "    \n",
    "#     print(r_precision(ps, vs))\n",
    "    rps.append(r_precision(ps, vs)) # append individual r-precision score\n",
    "    \n",
    "    # NDCG\n",
    "    r = np.zeros(len(ps))\n",
    "    for i, p in enumerate(ps):\n",
    "        if np.any(vs.isin([p])):\n",
    "            r[i] = 1\n",
    "    ndcgs.append(ndcg_at_k(r, len(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rp = np.mean(rps)\n",
    "avg_ndcg = np.mean(ndcgs)\n",
    "print('Avg. R-Precision: ', avg_rp)\n",
    "print('Avg. NDCG: ', avg_ndcg)\n",
    "print('Total Sum: ', np.mean([avg_rp, avg_ndcg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
